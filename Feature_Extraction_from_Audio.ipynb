{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction from Audio.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpjMOWw0drizAw6gTB5ddu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naseembabu/Audio-Detection/blob/main/Feature_Extraction_from_Audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87N3PFMIyeDP"
      },
      "source": [
        "https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWxpNtFlCNlW"
      },
      "source": [
        "(https://github.com/jameslyons/python_speech_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObMOsoZ1DtZ7"
      },
      "source": [
        "[Click here for dataset](http://www.voiptroubleshooter.com/open_speech/american.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taAfEtIpsRk8"
      },
      "source": [
        "import numpy\r\n",
        "import scipy.io.wavfile\r\n",
        "from scipy.fftpack import dct\r\n",
        "\r\n",
        "sample_rate, signal = scipy.io.wavfile.read('OSR_us_000_0010_8k.wav')  # File assumed to be in the same directory\r\n",
        "signal = signal[0:int(3.5 * sample_rate)]  # Keep the first 3.5 seconds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U78i6LuG4ovg"
      },
      "source": [
        "Apply pre-emphasis filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHXEe3lzy8cm"
      },
      "source": [
        "pre_emphasis = 0.97"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiQCBSIku17N"
      },
      "source": [
        "emphasized_signal = numpy.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8u_XS6EyZ0p"
      },
      "source": [
        "Framing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yJP_NIP40Cq"
      },
      "source": [
        "frame_size = 0.025\r\n",
        "frame_stride = 0.01"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6wrmO6L7Jeu"
      },
      "source": [
        "frame_length, frame_step = frame_size * sample_rate, frame_stride * sample_rate  # Convert from seconds to samples\r\n",
        "signal_length = len(emphasized_signal)\r\n",
        "frame_length = int(round(frame_length))\r\n",
        "frame_step = int(round(frame_step))\r\n",
        "num_frames = int(numpy.ceil(float(numpy.abs(signal_length - frame_length)) / frame_step))  # Make sure that we have at least 1 frame\r\n",
        "\r\n",
        "pad_signal_length = num_frames * frame_step + frame_length\r\n",
        "z = numpy.zeros((pad_signal_length - signal_length))\r\n",
        "pad_signal = numpy.append(emphasized_signal, z) # Pad Signal to make sure that all frames have equal number of samples without truncating any samples from the original signal\r\n",
        "\r\n",
        "indices = numpy.tile(numpy.arange(0, frame_length), (num_frames, 1)) + numpy.tile(numpy.arange(0, num_frames * frame_step, frame_step), (frame_length, 1)).T\r\n",
        "frames = pad_signal[indices.astype(numpy.int32, copy=False)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykvgs7Ac7-Fq"
      },
      "source": [
        "Window"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_zUM--_7_CR"
      },
      "source": [
        "frames *= numpy.hamming(frame_length)\r\n",
        "# frames *= 0.54 - 0.46 * numpy.cos((2 * numpy.pi * n) / (frame_length - 1))  # Explicit Implementation **"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cElQU_kK-Kzb"
      },
      "source": [
        "Fourier-Transform and Power Spectrum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUxmAvBc-L3G"
      },
      "source": [
        "NFFT = 512"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4boQPNW-loX"
      },
      "source": [
        "mag_frames = numpy.absolute(numpy.fft.rfft(frames, NFFT))  # Magnitude of the FFT\r\n",
        "pow_frames = ((1.0 / NFFT) * ((mag_frames) ** 2))  # Power Spectrum"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8amZUbg--unS"
      },
      "source": [
        "Filter Banks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKVTolxS_zSB"
      },
      "source": [
        "nfilt = 40"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTacXWw1-v9c"
      },
      "source": [
        "low_freq_mel = 0\r\n",
        "high_freq_mel = (2595 * numpy.log10(1 + (sample_rate / 2) / 700))  # Convert Hz to Mel\r\n",
        "mel_points = numpy.linspace(low_freq_mel, high_freq_mel, nfilt + 2)  # Equally spaced in Mel scale\r\n",
        "hz_points = (700 * (10**(mel_points / 2595) - 1))  # Convert Mel to Hz\r\n",
        "bin = numpy.floor((NFFT + 1) * hz_points / sample_rate)\r\n",
        "\r\n",
        "fbank = numpy.zeros((nfilt, int(numpy.floor(NFFT / 2 + 1))))\r\n",
        "for m in range(1, nfilt + 1):\r\n",
        "    f_m_minus = int(bin[m - 1])   # left\r\n",
        "    f_m = int(bin[m])             # center\r\n",
        "    f_m_plus = int(bin[m + 1])    # right\r\n",
        "\r\n",
        "    for k in range(f_m_minus, f_m):\r\n",
        "        fbank[m - 1, k] = (k - bin[m - 1]) / (bin[m] - bin[m - 1])\r\n",
        "    for k in range(f_m, f_m_plus):\r\n",
        "        fbank[m - 1, k] = (bin[m + 1] - k) / (bin[m + 1] - bin[m])\r\n",
        "filter_banks = numpy.dot(pow_frames, fbank.T)\r\n",
        "filter_banks = numpy.where(filter_banks == 0, numpy.finfo(float).eps, filter_banks)  # Numerical Stability\r\n",
        "filter_banks = 20 * numpy.log10(filter_banks)  # dB"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA6NjnVxARTp"
      },
      "source": [
        "[Mel-frequency Cepstral Coefficients (MFCCs)](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_a1Sx1NAeUl"
      },
      "source": [
        "num_ceps = 12\r\n",
        "cep_lifter = 22"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCZjyc5kAxUD"
      },
      "source": [
        "mfcc = dct(filter_banks, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # Keep 2-13"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpNW1UxGA52V"
      },
      "source": [
        "(nframes, ncoeff) = mfcc.shape\r\n",
        "n = numpy.arange(ncoeff)\r\n",
        "lift = 1 + (cep_lifter / 2) * numpy.sin(numpy.pi * n / cep_lifter)\r\n",
        "mfcc *= lift  #*"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hvKXRDcCdFJ"
      },
      "source": [
        "Mean Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk_OZADyCd8M"
      },
      "source": [
        "filter_banks -= (numpy.mean(filter_banks, axis=0) + 1e-8)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLYkm0mNCmVW"
      },
      "source": [
        "mfcc -= (numpy.mean(mfcc, axis=0) + 1e-8)"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}